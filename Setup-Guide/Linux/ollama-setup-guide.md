# DGX Spark: Ollama AI æœå‹™éƒ¨ç½² (å« Nginx è³‡å®‰é˜²è­·)

**ç’°å¢ƒèªªæ˜**

* **ç¡¬é«”**ï¼šGIGABYTE AI TOP ATOM (NVIDIA DGX Spark)
* **OS**ï¼šUbuntu 24.04 LTS
* **ç›®æ¨™**ï¼šéƒ¨ç½² Ollama (AI å¾Œç«¯) + Nginx (åå‘ä»£ç†/IP ç™½åå–®/éš±è—æª”é˜²è­·)
* **å°ˆæ¡ˆè·¯å¾‘**ï¼š`<your-dir>/ollama` (è«‹è‡ªè¡Œæ›¿æ›ç‚ºå¯¦éš›æ›è¼‰é»ï¼Œå¦‚ `/mnt/data/project/ollama`)

---

## ğŸ§ 1. æª¢æŸ¥èˆ‡å®‰è£ Docker (v2+)

DGX é€šå¸¸é è¼‰äº† Dockerï¼Œä½†æˆ‘å€‘éœ€è¦ç¢ºèªå…¶ç‰ˆæœ¬æ˜¯å¦æ”¯æ´ `docker compose` (V2)ã€‚

### 1.1 æª¢æŸ¥ç‰ˆæœ¬

è«‹å…ˆåŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤æª¢æŸ¥ç‰ˆæœ¬ï¼š

```bash
docker compose version
```

*   **è‹¥é¡¯ç¤º `Docker Compose version v2.x.x`**ï¼šä»£è¡¨ç’°å¢ƒå·²å°±ç·’ï¼Œè«‹**ç›´æ¥è·³è‡³ã€Œ2. å°ˆæ¡ˆç›®éŒ„èˆ‡æ¬Šé™è¨­å®šã€**ã€‚
*   **è‹¥é¡¯ç¤º command not found æˆ–ç‰ˆæœ¬éèˆŠ**ï¼šè«‹ä¾åºåŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿé€²è¡Œå®‰è£ã€‚

### 1.2 å®‰è£ Docker Engine (è‹¥ç’°å¢ƒæœªå°±ç·’)

#### è¨­å®š Repository èˆ‡ GPG é‡‘é‘°

é€™æ­¥æ˜¯ç‚ºäº†è®“ `apt` ä¿¡ä»» Docker å®˜æ–¹çš„è»Ÿé«”ä¾†æºï¼Œé¿å…å®‰è£åˆ°è¢«ç«„æ”¹çš„å¥—ä»¶ã€‚

ç§»é™¤èˆŠç‰ˆ (ç¢ºä¿ç’°å¢ƒä¹¾æ·¨)
```bash
sudo apt-get remove docker docker-engine docker.io containerd runc
```

å®‰è£å¿…è¦å‚³è¼¸å¥—ä»¶
```bash
sudo apt-get update
sudo apt-get install ca-certificates curl gnupg
```

ä¸‹è¼‰ Docker å®˜æ–¹ GPG å…¬é‘° (æ•¸ä½å°é‘‘)
```bash
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg
```

è¨­å®š Repo ä¾†æº
```bash
echo \
  "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
```

#### å®‰è£å¥—ä»¶

æ›´æ–°å¥—ä»¶æ¸…å–®
```bash
sudo apt-get update
```

å®‰è£æœ€æ–°ç‰ˆ Docker Engine èˆ‡ Compose Plugin
```bash
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

#### é©—è­‰å®‰è£

ç¢ºèª Compose ç‰ˆæœ¬ (æ‡‰é¡¯ç¤º v2.x.xï¼Œæ³¨æ„æŒ‡ä»¤æ²’æœ‰é€£å­—ç¬¦)
```bash
docker compose version
```

ç¢ºèª NVIDIA Container Toolkit æ˜¯å¦å­˜åœ¨ (DGX å¿…å‚™)
```bash
nvidia-ctk --version
```

---

## ğŸ“‚ 2. å°ˆæ¡ˆç›®éŒ„èˆ‡æ¬Šé™è¨­å®š

ä¾æ“šè³‡æ–™ç¢Ÿæ›è¼‰è¦ç¯„ï¼Œå»ºç«‹å°ˆæ¡ˆç›®éŒ„ä¸¦è¨­å®šæ¬Šé™ã€‚

1. å»ºç«‹ç›®éŒ„çµæ§‹ (å°‡ `<your-dir>` æ›¿æ›ç‚ºå¯¦éš›è·¯å¾‘ï¼Œä¾‹å¦‚ `/mnt/data/project/ollama/ollama_models`)
```bash
mkdir -p <your-dir>/ollama/ollama_models
```

2. è¨­å®šæ­¸å±¬æ¬Š (å°‡ `<username>` æ›¿æ›ç‚ºä½ çš„å¸³è™Ÿ)
```bash
sudo chown -R <username>:<username> <your-dir>/ollama
```

3. è¨­å®šç›®éŒ„æ¬Šé™ (éš±ç§ä¿è­·ï¼šå…¶ä»–äººç¦æ­¢é€²å…¥)
```bash
sudo chmod 700 <your-dir>/ollama
```

---

## âš™ï¸ 3. è¨­å®šæª”éƒ¨ç½²

æ‚¨å¯ä»¥ç›´æ¥å¾ [example-code/ollama/](../../example-code/ollama/) ç›®éŒ„ä¸­å–å¾—ä»¥ä¸‹æª”æ¡ˆï¼Œæˆ–æ‰‹å‹•å»ºç«‹ã€‚

è«‹åœ¨ `<your-dir>/ollama/` ç›®éŒ„ä¸‹å»ºç«‹ä»¥ä¸‹å…©å€‹æª”æ¡ˆã€‚

### 3.1 `nginx.conf` (è³‡å®‰å®ˆé–€å“¡)

* **åŠŸèƒ½**ï¼šIP ç™½åå–®éæ¿¾ã€éš±è—æª”å°é–ã€åå‘ä»£ç†ã€ä¸²æµå„ªåŒ–ã€‚

```nginx
worker_processes 1;

events {
    worker_connections 1024;
}

http {
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    server {
        # Nginx ç›£è½å®¹å™¨å…§çš„ 80 port (å°æ‡‰å¤–éƒ¨ 11434)
        listen 80;
        server_name localhost;

        # --- é˜²ç«ç‰†ç™½åå–® ACL ---
        
        # å…è¨± Docker å…§éƒ¨ç¶²æ®µ
        allow 10.168.89.0/24;

        # å…è¨±ä¿¡ä»» IP (è«‹è‡ªè¡Œå¢æ¸›)
        allow 127.0.0.1;
        allow 172.16.2.73; 
        allow 192.168.2.198;

        # æ‹’çµ•å…¶ä»–æ‰€æœ‰é€£ç·š (Default Deny)
        deny all;

        # > âš ï¸ **å°æ’‡æ­¥**ï¼šè‹¥å¾ŒçºŒæœ‰æ›´æ”¹ `nginx.conf` ä¸­çš„å…è¨± IPï¼Œè«‹åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤é‡æ–°è¼‰å…¥è¨­å®šï¼š
        # `docker restart ollama-nginx`

        # ç¦æ­¢å­˜å–éš±è—æª” (ä»¥ . é–‹é ­çš„æª”æ¡ˆ)
        location ~ /\. {
            deny all;
            access_log off;
            log_not_found off;
        }


        location / {
            # åå‘ä»£ç†åˆ° Ollama å®¹å™¨
            proxy_pass http://ollama:11434;

            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            
            # æ”¯æ´ LLM Streaming (æ‰“å­—æ©Ÿæ•ˆæœ)
            proxy_buffering off;
            
            # å»¶é•·è¶…æ™‚æ™‚é–“
            proxy_read_timeout 600s;
        }
    }
}
```

### 3.2 `docker-compose.yml` (æœå‹™ç·¨æ’)

> âš ï¸ **æ³¨æ„**ï¼šè«‹å°‡ volumes è·¯å¾‘ä¿®æ”¹ç‚ºä½ çš„ `<your-dir>`ã€‚

```yaml
version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    restart: always
    environment:
      - TZ=Asia/Taipei
      - OLLAMA_KEEP_ALIVE=5m
      - OLLAMA_MAX_LOADED_MODELS=3
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_HOST=0.0.0.0
    networks:
      ollama-net:
        ipv4_address: 10.168.89.2
    volumes:
      # è³‡æ–™è½åœ° (è«‹ä¿®æ”¹ <your-dir> ç‚ºå¯¦éš›è·¯å¾‘)
      - <your-dir>/ollama/ollama_models:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities: [gpu]

  nginx-guard:
    image: nginx:alpine
    container_name: ollama-nginx
    restart: always
    environment:
      - TZ=Asia/Taipei
    networks:
      ollama-net:
        ipv4_address: 10.168.89.3
    ports:
      # åªæœ‰ Nginx è² è²¬å°å¤–é–‹æ”¾ Port
      - "11434:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - /etc/localtime:/etc/localtime:ro

networks:
  ollama-net:
    driver: bridge
    ipam:
      config:
        - subnet: 10.168.89.0/24
```

---

## ğŸš€ 4. å•Ÿå‹•æœå‹™

åœ¨å°ˆæ¡ˆç›®éŒ„ä¸‹åŸ·è¡Œï¼š

å•Ÿå‹•æœå‹™
```bash
docker compose up -d
```

è‹¥ä¿®æ”¹éè¨­å®šæª”ï¼Œå¼·åˆ¶é‡å»º
```bash
docker compose up -d --force-recreate
```

---

## âœ… 5. é©—æ”¶æ¸¬è©¦ (Verification)

### 5.1 Postman æ¸¬è©¦ (é€£ç·šèˆ‡è³‡å®‰)

* **ç›®çš„**ï¼šç¢ºèª Nginx è½‰ç™¼æ­£å¸¸ï¼Œä¸”é˜²ç«ç‰†è¦å‰‡ç”Ÿæ•ˆã€‚
* **Method**: `POST`
* **URL**: `http://<Server-IP>:11434/api/generate`
* **Body (JSON)**:
```json
{
  "model": "llama3",
  "prompt": "Test connection",
  "stream": false
}
```


* **åˆ¤å®šæ¨™æº–**ï¼š
1. **æ­£å¸¸é€£ç·š**ï¼šStatus Code ç‚º `200 OK`ï¼Œä¸¦å›å‚³ JSON çµæœã€‚
2. **IP å°é–æ¸¬è©¦** (ä½¿ç”¨æ‰‹æ©Ÿ 4G æ¸¬è©¦)ï¼šæ‡‰å›å‚³ `403 Forbidden`ã€‚
3. **éš±è—æª”æ¸¬è©¦** (GET `http://<Server-IP>:11434/.env`)ï¼šæ‡‰å›å‚³ `403 Forbidden`ã€‚



### 5.2 curl æ¸¬è©¦ (Streaming ä¸²æµ)

* **ç›®çš„**ï¼šç¢ºèª Nginx æ²’æœ‰å¡ä½ä¸²æµç·©è¡ï¼Œèƒ½å¯¦ç¾æ‰“å­—æ©Ÿæ•ˆæœã€‚
* **æŒ‡ä»¤** (è«‹åœ¨çµ‚ç«¯æ©ŸåŸ·è¡Œ)ï¼š

`N` åƒæ•¸æ˜¯é—œéµ (No buffer)
```bash
curl -N -X POST http://<Server-IP>:11434/api/generate \
  -d '{
    "model": "llama3",
    "prompt": "è«‹è‡ªæˆ‘ä»‹ç´¹",
    "stream": true
  }'
```


* **åˆ¤å®šæ¨™æº–**ï¼š
* çµ‚ç«¯æ©Ÿç•«é¢æ‡‰**ä¸€è¡Œä¸€è¡Œ**å³æ™‚è·³å‡º JSON è³‡æ–™ã€‚
* è‹¥å¡ä½è¨±ä¹…æ‰ä¸€æ¬¡å…¨éƒ¨å™´å‡ºï¼Œä»£è¡¨ `proxy_buffering off;` è¨­å®šæœªç”Ÿæ•ˆã€‚

### 5.3 GPU ç‹€æ…‹æª¢æŸ¥ (GPU Status)

* **ç›®çš„**ï¼šç¢ºèª Ollama å®¹å™¨æ˜¯å¦æ­£ç¢ºæŠ“å–åˆ° GPU è³‡æºã€‚

åŸ·è¡ŒæŒ‡ä»¤
```bash
docker exec -it ollama nvidia-smi
```

* **åˆ¤å®šæ¨™æº–**ï¼š
* æ‡‰é¡¯ç¤º NVIDIA é¡¯ç¤ºå¡ç‹€æ…‹è¡¨ (å¦‚ GPU å‹è™Ÿã€è¨˜æ†¶é«”ä½¿ç”¨é‡)ã€‚
* è‹¥é¡¯ç¤º `command not found` æˆ–éŒ¯èª¤è¨Šæ¯ï¼Œè«‹æª¢æŸ¥ `docker-compose.yml` ä¸­çš„ `deploy.resources` è¨­å®šã€‚

---

## ğŸ”§ 6. ç°¡æ˜“æ•…éšœæ’é™¤ (Troubleshooting)

Log æª¢æŸ¥ (åŸºæœ¬åŠŸ) - æŸ¥ Nginx è¨­å®šéŒ¯èª¤
```bash
docker logs ollama-nginx
```

æŸ¥ GPU/æ¨¡å‹è¼‰å…¥éŒ¯èª¤
```bash
docker logs ollama
```


* **Nginx 403 Forbidden**ï¼šæª¢æŸ¥ Client IP æ˜¯å¦å·²åŠ å…¥ `nginx.conf` çš„ `allow` æ¸…å–®ã€‚
* **é€£ç·šè¢«æ‹’ (Connection Refused)**ï¼š
1. æª¢æŸ¥ UFW é˜²ç«ç‰†ï¼š`sudo ufw status` (éœ€ allow 11434)ã€‚
2. æª¢æŸ¥å®¹å™¨ç‹€æ…‹ï¼š`docker compose ps` (éœ€ç‚º Up)ã€‚


---

## âš ï¸ è³‡å®‰é¢¨éšªæç¤ºèˆ‡æœªä¾†è£œå¼·å»ºè­°

ç›®å‰çš„éƒ¨ç½²æ¶æ§‹ï¼ˆNginx åå‘ä»£ç† + IP ç™½åå–® + éš±è—æª”é˜²è­·ï¼‰å·²å…·å‚™åŸºç¤é˜²è­·èƒ½åŠ›ï¼Œå„ªæ–¼å¤šæ•¸ç›´æ¥é–‹æ”¾ `0.0.0.0` çš„é è¨­ç’°å¢ƒã€‚ç„¶è€Œåœ¨ä¼æ¥­è³‡å®‰æ¨™æº–ä¸‹ï¼Œå»ºè­°ç•™æ„ä»¥ä¸‹é¢¨éšªä¸¦è¦–éœ€æ±‚é€²è¡Œå„ªåŒ–ã€‚

### 1. ç¾è¡Œæ¶æ§‹é¢¨éšªæ­éœ² (Risk Disclosure)

æœ¬æ–¹æ¡ˆç›®å‰åƒ…å»ºè­°é‹è¡Œæ–¼**ã€Œå—ä¿¡ä»»çš„å°é–‰å…§ç¶²ç’°å¢ƒã€**ï¼š

*   **æ˜æ–‡å‚³è¼¸é¢¨éšª (Cleartext Transmission)**ï¼š
    ç›®å‰æœå‹™é‹è¡Œæ–¼ `HTTP` å”å®šï¼Œè³‡æ–™åœ¨å…§ç¶²å‚³è¼¸éç¨‹ä¸­çš†ç‚ºæ˜æ–‡ã€‚è‹¥å…§ç¶²ä¸­å­˜åœ¨æƒ¡æ„å—…æ¢å·¥å…·ï¼ˆå¦‚ Wiresharkï¼‰ï¼Œé€£ç·šå…§å®¹å¯èƒ½è¢«æˆªç²ã€‚**è«‹å‹¿è¼¸å…¥æ©Ÿæ•å€‹è³‡æˆ–å…¬å¸æ ¸å¿ƒæ©Ÿå¯†ã€‚**
*   **èªæ©Ÿä¸èªäºº (Device-Based Trust)**ï¼š
    é©—è­‰æ©Ÿåˆ¶åƒ…åŸºæ–¼ä¾†æº IPã€‚è‹¥ç™½åå–®å…§çš„è¨­å‚™å®‰å…¨æ€§å—æï¼Œæ”»æ“Šè€…å¯èƒ½è—‰æ­¤å­˜å– AI æœå‹™ã€‚

### 2. æœªä¾†è£œå¼·å»ºè­° (Roadmap)

è‹¥æœå‹™éœ€æ“´å¤§ä½¿ç”¨è¦æ¨¡æˆ–ç¬¦åˆè³‡å®‰ç¨½æ ¸æ¨™æº–ï¼Œå»ºè­°å¯¦æ–½ä»¥ä¸‹é˜²è­·ï¼š

*   **åŠ å¯†å‚³è¼¸ (HTTPS)**ï¼šå°å…¥ SSL/TLS æ†‘è­‰ï¼Œé˜²æ­¢ä¸­é–“äººæ”»æ“Š (MITM) èˆ‡å…§å®¹ç«Šè½ã€‚
*   **èº«åˆ†é©—è­‰ (Authentication)**ï¼š
    *   **çŸ­æœŸ**ï¼šæ–¼ Nginx å•Ÿç”¨ `Basic Auth` é€²è¡Œå¸³å¯†é©—è­‰ã€‚
    *   **é•·æœŸ**ï¼šæ•´åˆ OIDC æˆ– LDAP (SSO) ç³»çµ±ã€‚
*   **API Key ç®¡ç†**ï¼šç‚ºä¸åŒæ‡‰ç”¨ç¨‹å¼æ ¸ç™¼ç¨ç«‹ API Keyï¼Œä»¥ä¾¿è¿½è¹¤æµé‡èˆ‡æ§ç®¡æ¬Šé™ã€‚
*   **ç¨½æ ¸ç´€éŒ„ (Audit Logging)**ï¼šå°‡ Log æ‹‹é€è‡³é›†ä¸­å¼æ—¥èªŒä¼ºæœå™¨ (å¦‚ ELK)ï¼Œä»¥ç¬¦åˆç¨½æ ¸è¦ç¯„ã€‚